{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c772a4f6-3278-4605-a9a4-c6a3995c6fd1",
   "metadata": {},
   "source": [
    "# Tutorial for extracting graph represenatations of all images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2131d7a-3cc8-416b-9e0c-415a222a9abb",
   "metadata": {},
   "source": [
    "## Step 1: Register images from the same FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80fa32a8-1818-4e30-bade-5be2e32b8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "from pathlib import Path\n",
    "from novas3d.registration import ImageRegistration\n",
    "import pickle\n",
    "from os import mkdir\n",
    "from os.path import exists\n",
    "from novas3d.utilities import get_mov_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aadd00d-3a0b-44ee-bab9-3b6f28d5ab05",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'novas3d_example_data/matched_stacks_init.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3924620/1802450547.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load dictionary for matched volumes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'novas3d_example_data/matched_stacks_init.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'67/XYZres387'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'novas3d_example_data/matched_stacks_init.pickle'"
     ]
    }
   ],
   "source": [
    "#load dictionary for matched volumes\n",
    "with open('novas3d_example_data/matched_stacks_init.pickle', 'rb') as f:\n",
    "    dic = pickle.load(f)\n",
    "sorted(dic['67/XYZres387'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d3986-cbd5-42ba-b94a-3584251e1d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids_path = Path('novas3d_example_data/')#each mouse has its own folder with raw data in it\n",
    "mouse_ids = list(mouse_ids_path.glob('*?[0-9]/*res*?[0-9].tif'))#grab folder names/mouse ids\n",
    "images = sorted([x.as_posix() for x in mouse_ids if '_0001' not in x.as_posix()])\n",
    "images = [x for x in images if  any(y in x for y in list(dic.keys()))]\n",
    "\n",
    "unused_keys = [x for x in list(dic.keys()) if not  any(x in y for y in images)]\n",
    "print(len(images))\n",
    "shuffle(images)\n",
    "params = { \n",
    "    'out_directory': 'novas3d_example_data/raw_warped/', # path to output directory\n",
    "    'in_filename_extension': '.tif', # initial filename extension of unregistered images\n",
    "    'final_filename_extension': '_warped.tif', # modified filename extension following registration\n",
    "    'timepoint_suffixes': ['_0001'], # list of all timepoint suffixes present ie _0001, _0002, _0003, ...\n",
    "    'sigma': 2, # Smoothing sigma applied to iamges prior to registration, used by ANTs rigid registration\n",
    "    'flip': True, # flip images based on direction of aquision to match the reference. ONly works for files that were origionally olympus oir files\n",
    "    'dic': dic # dictionary of matched aqusitions\n",
    "}\n",
    "\n",
    "if not exists(params['out_directory']):\n",
    "    mkdir(params['out_directory'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5655493",
   "metadata": {},
   "source": [
    "*class ImageRegistration(images, out_directory, in_filename_extension, final_filename_extension, timepoint_suffixes, sigma, flip, dic, skip_finished=False)*\n",
    "\n",
    "Register images using ANTs registration.\n",
    "\n",
    "**Args:**\n",
    "- **images (list):** List of image files to register. Each time point should be its own file. Files should be tif stacks. Channel 1 should be the colour channel.\n",
    "- **out_directory (str):** Output directory to save the registered images.\n",
    "- **in_filename_extension (str):** Initial filename extension of the unregistered images.\n",
    "- **final_filename_extension (str):** Final filename extension of the registered images.\n",
    "- **timepoint_suffixes (list):** List of timepoint suffixes.\n",
    "- **sigma (float):** Sigma value for the registration.\n",
    "- **flip (bool):** Whether to flip the moving image based on metadata. (only works on images acquired with an Olympus system, set to false if not sure if images were acquired on an Olympus microscope)\n",
    "- **dic (dict):** A dictionary of the image files with a reference image as the key and a list of moving images as the value.\n",
    "- **skip_existing (bool):** Whether to skip already registered images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d73ad7-92e8-45fc-b159-3428bf9fa671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ImageRegistration class\n",
    "registration = ImageRegistration(images = images, \n",
    "                                 out_directory = params['out_directory'], \n",
    "                                 in_filename_extension = params['in_filename_extension'], \n",
    "                                 final_filename_extension = params['final_filename_extension'], \n",
    "                                 timepoint_suffixes = params['timepoint_suffixes'], \n",
    "                                 sigma = params['sigma'], \n",
    "                                 flip = params['flip'], \n",
    "                                 dic = params['dic'],\n",
    "                                 skip_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e09c7-fd84-452d-ab3f-57761d9e5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the register_images method\n",
    "registration.register_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2abe512-a56c-42de-a92c-9f0617eee6e3",
   "metadata": {},
   "source": [
    "## Step 2: Predict segmentation results\n",
    "\n",
    "### !!! Faster With GPUs !!!\n",
    "\n",
    "Requires GPUs with 40 GB vRAM otherwise disable GPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b78c2be5-b4f4-41eb-b3d8-088608884d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from pathlib import Path\n",
    "from re import sub\n",
    "import warnings\n",
    "from numpy.random import shuffle\n",
    "from novas3d.predict import PredictWarped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57fe8a1e-783b-438f-920f-f6352529462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the mouse data\n",
    "image_path = Path('novas3d_example_data/raw_warped')\n",
    "images = list(image_path.glob('*res*.tif'))\n",
    "images = sorted([x.as_posix() for x in images])\n",
    "shuffle(images)\n",
    "\n",
    "# Create data dictionaries for prediction\n",
    "params = {\n",
    "    \"in_dir\": \"novas3d_example_data/raw_warped\", # imput directory of files to segment\n",
    "    \"out_dir\": \"novas3d_example_data/raw_warped_seg\", # output directory for files after segmentation\n",
    "    \"num_evals\": 3, # number of evaluations for the ensemble to predict with\n",
    "    \"base_file_extension\": \".tif\", # base file extension\n",
    "    \"pred_file_extension\": \"_pred.npy\", # predicted probabilities filename extension\n",
    "    \"mean_file_extension\": \"_mean.npy\", # mean probabilities filename extension\n",
    "}\n",
    "\n",
    "if not exists(params['out_dir']):\n",
    "    mkdir(params['out_dir'])\n",
    "\n",
    "##################################################################################################################\n",
    "# STD will be calcualted later on an allocation without GPUs, this takes up alot of CPU time leaving GPUs idol\n",
    "##################################################################################################################\n",
    "\n",
    "data_dict = [\n",
    "    {\"image\": image_name}\n",
    "    for image_name in images if not exists(sub(params[\"base_file_extension\"], params[\"pred_file_extension\"], sub(params[\"in_dir\"], params[\"out_dir\"], image_name)))\n",
    "]\n",
    "\n",
    "print(len(data_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be78513",
   "metadata": {},
   "source": [
    "*class PredictWarped(images, out_directory, in_filename_extension, final_filename_extension, timepoint_suffixes, sigma, flip, dic, skip_finished=False)*\n",
    "\n",
    "Class for Performing Prediction Using the Registered Images. Saves the predicted images.\n",
    "\n",
    "**Args:**\n",
    "- **data_dict (dict):** A dictionary containing the data for prediction.\n",
    "- **config (dict):** A dictionary containing the configuration parameters.\n",
    "    - **in_dir (str):** The input directory.\n",
    "    - **out_dir (str):** The output directory.\n",
    "    - **num_evals (int):** The number of evaluations.\n",
    "    - **base_file_extension (str):** The base file extension.\n",
    "    - **pred_file_extension (str):** The prediction file extension.\n",
    "    - **mean_file_extension (str):** The mean file extension.\n",
    "- **parameter_file (str):** The file path to the parameter file.\n",
    "- **spatial_dims (int):** The number of spatial dimensions.\n",
    "- **in_channels (int):** The number of input channels.\n",
    "- **out_channels (int):** The number of output channels.\n",
    "- **img_size (tuple):** The size of the input image.\n",
    "- **feature_size (int):** The size of the features.\n",
    "- **hidden_size (int):** The size of the hidden layers.\n",
    "- **mlp_dim (int):** The dimension of the MLP layers.\n",
    "- **pos_embed (bool):** Whether to use positional embedding.\n",
    "- **res_block (bool):** Whether to use residual blocks.\n",
    "- **norm_name (str):** The name of the normalization method.\n",
    "- **spacing (tuple):** The spacing between voxels. Reciprocal of the voxel size in um to resample to 1 um.\n",
    "- **i_min (float):** The minimum intensity value of raw images.\n",
    "- **i_max (float):** The maximum intensity value of raw images.\n",
    "- **b_min (float):** The minimum background value after normalization.\n",
    "- **b_max (float):** The maximum background value after normalization.\n",
    "- **clip (bool):** Whether to clip the values.\n",
    "- **channel_dim (int):** The dimension index of the colour channel.\n",
    "- **gpu (bool):** Whether to use the GPU.\n",
    "- **skip_existing (bool):** Whether to skip images that have already been predicted.\n",
    "\n",
    "**Methods:**\n",
    "- **get_model():** Retrieves the model for prediction.\n",
    "- **get_pred_transforms():** Retrieves the prediction transforms.\n",
    "- **dataset_creation():** Creates the dataset for prediction.\n",
    "- **prediction():** Performs the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67969368-f19b-4363-bf0d-39d8e41d2153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 7.78 GiB total capacity; 3.30 GiB already allocated; 697.25 MiB free; 4.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m PredictMatt \u001b[38;5;241m=\u001b[39m PredictWarped(data_dict, \n\u001b[1;32m      2\u001b[0m                             params,\n\u001b[1;32m      3\u001b[0m                             parameter_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperparameter_pickle_files/parameters436.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m                             clip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     20\u001b[0m                             channel_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mPredictMatt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/novas3d/novas3d/predict.py:453\u001b[0m, in \u001b[0;36mPredictWarped.prediction\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(sub(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_file_extension\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_file_extension\u001b[39m\u001b[38;5;124m\"\u001b[39m], sub(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dict[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]))):\n\u001b[1;32m    452\u001b[0m     new_file_name \u001b[38;5;241m=\u001b[39m sub(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dict[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 453\u001b[0m     pred_array \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_evals\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m#self.assertIsNotNone(pred_array)\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     mean \u001b[38;5;241m=\u001b[39m float16(pred_array\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/Downloads/novas3d/novas3d/predict.py:260\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(pred_data, num_evals, num_channels_out, model, device, roi_size, sw_batch_size)\u001b[0m\n\u001b[1;32m    258\u001b[0m softmax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Perform sliding window inference\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m pred_outputs \u001b[38;5;241m=\u001b[39m \u001b[43msliding_window_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroi_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43msw_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43msw_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Apply softmax to the predicted outputs\u001b[39;00m\n\u001b[1;32m    270\u001b[0m pred_outputs \u001b[38;5;241m=\u001b[39m softmax(pred_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/monai/inferers/utils.py:130\u001b[0m, in \u001b[0;36msliding_window_inference\u001b[0;34m(inputs, roi_size, sw_batch_size, predictor, overlap, mode, sigma_scale, padding_mode, cval, sw_device, device, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m unravel_slice \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    126\u001b[0m     [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m num_win), \u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m num_win) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(slices[idx \u001b[38;5;241m%\u001b[39m num_win])\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m slice_range\n\u001b[1;32m    128\u001b[0m ]\n\u001b[1;32m    129\u001b[0m window_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([inputs[win_slice] \u001b[38;5;28;01mfor\u001b[39;00m win_slice \u001b[38;5;129;01min\u001b[39;00m unravel_slice])\u001b[38;5;241m.\u001b[39mto(sw_device)\n\u001b[0;32m--> 130\u001b[0m seg_prob \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# batched patch segmentation\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _initialized:  \u001b[38;5;66;03m# init. buffer at the first iteration\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     output_classes \u001b[38;5;241m=\u001b[39m seg_prob\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:166\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m ({},)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m    168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/monai/networks/nets/unetr.py:191\u001b[0m, in \u001b[0;36mUNETR.forward\u001b[0;34m(self, x_in)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_in):\n\u001b[0;32m--> 191\u001b[0m     x, hidden_states_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     enc1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder1(x_in)\n\u001b[1;32m    193\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m hidden_states_out[\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/monai/networks/nets/vit.py:107\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m hidden_states_out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 107\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     hidden_states_out\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    109\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/monai/networks/blocks/transformerblock.py:48\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 48\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/novas3d/lib/python3.8/site-packages/monai/networks/blocks/selfattention.py:53\u001b[0m, in \u001b[0;36mSABlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     52\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqkv(x), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb h (qkv l d) -> qkv b l h d\u001b[39m\u001b[38;5;124m\"\u001b[39m, qkv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, l\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n\u001b[0;32m---> 53\u001b[0m     att_mat \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblxd,blyd->blxy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m)\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m     att_mat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_weights(att_mat)\n\u001b[1;32m     55\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhxy,bhyd->bhxd\u001b[39m\u001b[38;5;124m\"\u001b[39m, att_mat, v)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 7.78 GiB total capacity; 3.30 GiB already allocated; 697.25 MiB free; 4.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "PredictMatt = PredictWarped(data_dict, \n",
    "                            params,\n",
    "                            parameter_file='NOVAS3D_Vessel_and_Neuron_Segmentation/parameters.pickle', \n",
    "                            spatial_dims=3, \n",
    "                            in_channels=2, \n",
    "                            out_channels=3, \n",
    "                            img_size=(128,128,128), \n",
    "                            feature_size=16, \n",
    "                            hidden_size=768, \n",
    "                            mlp_dim=3072, \n",
    "                            pos_embed=\"perceptron\",\n",
    "                            res_block=True, \n",
    "                            norm_name=\"instance\",\n",
    "                            spacing=(1, 1, 0.375), \n",
    "                            i_min=0, \n",
    "                            i_max=1024, \n",
    "                            b_min=0.0, \n",
    "                            b_max=1.0, \n",
    "                            clip=True, \n",
    "                            channel_dim=0,\n",
    "                            gpu=False,\n",
    "                            skip_existing=True)\n",
    "PredictMatt.prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089584b-139c-4651-bf0c-020a0e695a19",
   "metadata": {},
   "source": [
    "## Step 3: Calculate STD of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7badb459-42d7-49f6-9e65-0d36eaadeff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from re import sub\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from numpy.random import shuffle\n",
    "from novas3d.vessel_graph import SaveStdFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b4876-3b5c-42b1-ab91-871135608865",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"data_directory\": \"novas3d_example_data/raw_warped_seg\", #location of output probabilities from prediction\n",
    "    \"in_directory\": \"novas3d_example_data/raw_warped_seg\",\n",
    "    \"out_directory\": \"novas3d_example_data/raw_warped_seg\",\n",
    "    \"init_tag\": 'pred', # tag for the predicited probabilities array in step 2 \"pred_file_extension\"\n",
    "    \"final_tag\": 'std', # tag to save the standard deviation of the predicted probabiliteis under\n",
    "    \"skip_existing\": True, # skip files that have already been processed\n",
    "}\n",
    "\n",
    "if not exists(params['out_directory']):\n",
    "    mkdir(params['out_directory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6d61c-c716-40bf-b744-ec8fd86aaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the files list\n",
    "path = Path(params[\"data_directory\"])\n",
    "files = list(path.glob('*_' + params['init_tag'] + '.npy'))\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "files = [x for x in files if not exists(sub(params['in_directory'], params['out_directory'], sub(params['init_tag'], params['final_tag'], x)))]\n",
    "print(len(files))\n",
    "\n",
    "# Shuffle the files list\n",
    "shuffle(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce614f69",
   "metadata": {},
   "source": [
    "*class SaveStdFile(files, in_directory, out_directory, in_tag, final_tag,skip_existing=False)*\n",
    "\n",
    "Initialize SaveStdFile Instance\n",
    "\n",
    "This section initializes an instance of the `SaveStdFile` class, calculates the standard deviation for predicted data, and saves the standard deviation files.\n",
    "\n",
    "**Args:**\n",
    "- **files (list):** List of file paths.\n",
    "- **in_directory (str):** Input directory path.\n",
    "- **out_directory (str):** Output directory path.\n",
    "- **in_tag (str):** Initial tag.\n",
    "- **final_tag (str):** Final tag.\n",
    "- **skip_existing (bool):** Skip files where std already exists.\n",
    "\n",
    "**Methods:**\n",
    "- **std():** Save the standard deviation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc57f72-1d39-4ad6-af63-81c22a9a1901",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create an instance of the SaveStdFile class with the files list and other parameters\n",
    "save_std = SaveStdFile(files, params['in_directory'], params['out_directory'], params['init_tag'], params['final_tag'], params['skip_finished'])\n",
    "# Save the standard deviation files\n",
    "save_std.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5a203-af19-404f-8612-52a6b7feeb95",
   "metadata": {},
   "source": [
    "## Step 4: Binarize Vascular predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c7855-51c0-410a-8623-0d046dcb29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from numpy.random import shuffle\n",
    "from pathlib import Path\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from novas3d.vessel_graph import Binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b41fe6-7f1c-4297-a0d0-ecddd9d70233",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('novas3d_example_data/raw_warped_seg')\n",
    "files  = directory.glob('*-*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(len(files))\n",
    "\n",
    "parameters = {\n",
    "    'min_prob': 0.75, # minimum probability for binarization to classify a voxel as a vessel\n",
    "    'max_var': 0.2, # maximum standard deviation for binarization to classify a voxel as a vessel\n",
    "    'in_directory': \"novas3d_example_data/raw_warped_seg\", # input directory\n",
    "    'out_directory': \"novas3d_example_data/raw_warped_seg\", # output directory\n",
    "    'mean_tag': 'mean', # tag for mean probaility\n",
    "    'std_tag': 'std', # tag for mean standard deviation of probability\n",
    "    'seg_tag': 'seg' # output tag for segmentation\n",
    "}\n",
    "\n",
    "if not exists(params['out_directory']):\n",
    "    mkdir(params['out_directory'])\n",
    "\n",
    "shuffle(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5106ae9-e814-47e9-b58e-ab2f8e6b4523",
   "metadata": {},
   "source": [
    "*class Binarize(files, min_prob, max_var, in_directory, out_directory, mean_tag, std_tag, seg_tag, skip_existing=False)*\n",
    "Initializes the `Binarize` class. This class is used to binarize the files in the specified directory based on mean and standard deviation thresholds.\n",
    "\n",
    "**Args:**\n",
    "- **directory (str):** The directory path.\n",
    "- **min_prob (float):** The minimum probability threshold.\n",
    "- **max_var (float):** The maximum variance threshold.\n",
    "- **in_directory (str):** The input directory path.\n",
    "- **out_directory (str):** The output directory path.\n",
    "- **mean_tag (str):** The mean tag.\n",
    "- **std_tag (str):** The standard deviation tag.\n",
    "- **seg_tag (str):** The segmentation tag.\n",
    "- **skip_existing (bool):** Skip existing files that have already been binarized.\n",
    "\n",
    "**Methods:**\n",
    "- **binarize_files():** Binarizes the files in the directory.\n",
    "- **get_files():** Retrieves the list of files in the directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc22b8-d0b4-4dea-9dca-0468b75abeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = Binarize(files = files,\n",
    "                     min_prob = parameters['min_prob'],\n",
    "                     max_var = parameters['max_var'], \n",
    "                     in_directory = parameters['in_directory'],\n",
    "                     out_directory = parameters['out_directory'], \n",
    "                     mean_tag = parameters['mean_tag'],\n",
    "                     std_tag = parameters['std_tag'],\n",
    "                     seg_tag = parameters['seg_tag'],\n",
    "                     skip_existing=True)\n",
    "\n",
    "binarizer.binarize_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27b5e8-4279-4022-8c8f-0ff4e488f0a2",
   "metadata": {},
   "source": [
    "## Step 4a: binarize neuron segmentation and calculate distances from every nonneuron pixel to the closest neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dad583-78bb-45e6-8784-c368301bcd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from novas3d.vessel_graph import NeuronDistanceCalculator\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from re import sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02926b-4843-489c-9ca8-ec4e90861503",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('novas3d_example_data/raw_warped_seg')\n",
    "files  = directory.glob('*-*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "files = [x for x in files if not exists(sub('_mean.npy', '_seg_nrn.npy', x))]\n",
    "print(len(files))\n",
    "\n",
    "parameters = {\n",
    "    'min_prob': 0.75,\n",
    "    'max_var': 0.1,\n",
    "    'in_directory': 'novas3d_example_data/raw_warped_seg',\n",
    "    'out_directory': 'novas3d_example_data/raw_warped_seg',\n",
    "    'mean_tag': 'mean',\n",
    "    'std_tag': 'std',\n",
    "    'neuron_distance_tag': 'seg_nrn_dst',\n",
    "    'seg_tag': 'seg',\n",
    "    'seg_nrn_tag': 'seg_nrn'   \n",
    "}\n",
    "\n",
    "if not exists(params['out_directory']):\n",
    "    mkdir(params['out_directory'])\n",
    "\n",
    "np.random.shuffle(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab105496-7d97-4a5c-bc3e-3860722bc9f6",
   "metadata": {},
   "source": [
    "*class NeuronDistanceCalculator(files, min_prob, max_var, in_directory, out_directory, mean_tag, std_tag, neuron_distance_tag, seg_tag, seg_nrn_tag,skip_existing=False)*\n",
    "Calculates the distance between neurons based on given parameters. Saves the distance transform of the Neuron segmentation array.\n",
    "\n",
    "**Args:**\n",
    "- **files (list):** List of file paths.\n",
    "- **min_prob (float):** Minimum probability threshold.\n",
    "- **max_var (float):** Maximum variance threshold.\n",
    "- **in_directory (str):** Input directory path.\n",
    "- **out_directory (str):** Output directory path.\n",
    "- **mean_tag (str):** Tag for mean values.\n",
    "- **std_tag (str):** Tag for standard deviation values.\n",
    "- **neuron_distance_tag (str):** Tag for neuron distance values.\n",
    "- **seg_tag (str):** Tag for segmentation values.\n",
    "- **seg_nrn_tag (str):** Tag for segmented neuron values.\n",
    "- **skip_existing (bool):** Whether to skip images that have already been predicted.\n",
    "\n",
    "**Methods:**\n",
    "- **calculate_distance():** Calculates the distance between neurons for each file in the given list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42941c-fa8b-42d9-ad82-0dc4ce9caa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = NeuronDistanceCalculator(files, \n",
    "                             parameters['min_prob'], \n",
    "                             parameters['max_var'], \n",
    "                             parameters['in_directory'], \n",
    "                             parameters['out_directory'], \n",
    "                             parameters['mean_tag'], \n",
    "                             parameters['std_tag'], \n",
    "                             parameters['neuron_distance_tag'], \n",
    "                             parameters['seg_tag'], \n",
    "                             parameters['seg_nrn_tag'],\n",
    "                             skip_existing=True)\n",
    "n.calculate_distance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d64d1-0f3a-430b-ae23-dd6f44145813",
   "metadata": {},
   "source": [
    "## Step 5: Calculate union of matched files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984eb38a-b4e7-4490-b874-91fefaf91076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "from pathlib import Path\n",
    "from re import sub\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "import pickle\n",
    "from vessel_morphology.vessel_graph import SegmentationMaskUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc74f1-7216-4123-a19a-61a11ef79d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('novas3d_example_data/matched_stacks.pickle', 'rb') as handle:\n",
    "    dic = pickle.load(handle)\n",
    "    \n",
    "directory_seg = Path('novas3d_example_data/raw_warped_seg')\n",
    "images = list(directory_seg.glob('*_0001_warped_seg.npy'))\n",
    "images = sorted([x.as_posix() for x in images])\n",
    "images = [x for x in images if exists(sub('_0001','',x))]\n",
    "images = [x for x in images if any(y in x for y in list(dic.keys()))]\n",
    "\n",
    "params = {'IOU_thresh':0.2,\n",
    "        'input_directory':'novas3d_example_data/raw_warped_seg',\n",
    "        'output_directory':'novas3d_example_data/raw_warped_seg',\n",
    "        'initial_suffix':'_warped_seg.npy',\n",
    "        'final_suffix_mat':'_seg_warped_single.mat',\n",
    "        'final_suffix_npy':'_seg_warped_single.npy',\n",
    "        'timepoint_suffixes':['_0001'],\n",
    "        'thresh_remove_small_comps':250,\n",
    "        'thresh_fill_holes':1000,\n",
    "        'n_interations_binary_closing':3,\n",
    "        }\n",
    "\n",
    "if not exists(params['output_directory']):\n",
    "    mkdir(params['output_directory'])\n",
    "\n",
    "shuffle(images)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe753d1-09e7-48da-b13d-476dfc1bf15f",
   "metadata": {},
   "source": [
    "*class SegmentationMaskUnion(files, dic, in_directory, out_directory, in_suffix, final_suffix_mat, final_suffix_npy, timepoint_suffixes, IOU_thresh, thresh_fill_holes, thresh_remove_small_comps, n_interations_binary_closing,skip_existing=False)*\n",
    "\n",
    "Process a list of images by performing binary dilation, calculating intersection over union (IOU), performing post-processing, and saving the processed images as .mat and .npy files.\n",
    "\n",
    "**Args:**\n",
    "- **files (list):** List of image file paths.\n",
    "- **dic (dict):** Dictionary containing additional information.\n",
    "- **in_directory (str):** Path to the input directory.\n",
    "- **out_directory (str):** Path to the output directory.\n",
    "- **in_suffix (str):** Suffix of the initial files.\n",
    "- **final_suffix_mat (str):** Suffix of the final .mat files.\n",
    "- **final_suffix_npy (str):** Suffix of the final .npy files.\n",
    "- **timepoint_suffixes (list):** List of timepoint suffixes. ex: ['_0001', '_0002', '_0003']\n",
    "- **IOU_thresh (float):** Intersection over Union (IOU) threshold.\n",
    "- **thresh_fill_holes (int):** Threshold for filling holes in the segmented image.\n",
    "- **thresh_remove_small_comps (int):** Threshold for removing small connected components in the segmented image.\n",
    "- **n_interations_binary_closing (int):** Number of iterations for binary closing.\n",
    "- **skip_existing (bool):** Skip existing files that have already been processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a796e-db29-4746-b564-2d62a374e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ImageProcessor and process the images\n",
    "processor = SegmentationMaskUnion(images, \n",
    "                                  dic,\n",
    "                                  params['input_directory'], \n",
    "                                  params['output_directory'], \n",
    "                                  params['initial_suffix'], \n",
    "                                  params['final_suffix_mat'], \n",
    "                                  params['final_suffix_npy'],\n",
    "                                  params['timepoint_suffixes'], \n",
    "                                  params['IOU_thresh'], \n",
    "                                  params['thresh_fill_holes'], \n",
    "                                  params['thresh_remove_small_comps'],\n",
    "                                  params['n_interations_binary_closing'],\n",
    "                                  skip_existing=True\n",
    "                                  )\n",
    "                                  \n",
    "processor.process_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52209fa3-23d8-4c1a-8b52-db1c9204ecfd",
   "metadata": {},
   "source": [
    "## Step 6: Generate Skeletons from the Union of the segmentation masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b059447-e4b3-47c6-be64-c8d9c16ea2af",
   "metadata": {},
   "source": [
    "Run the following code in matlab after modifying the following matlab file gen_skeletons_warped_single.m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a4986-e2dd-4374-893c-3333b58b68f7",
   "metadata": {},
   "source": [
    "module load matlab \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008a1ac-cf98-499c-8cc5-d2de08927b43",
   "metadata": {},
   "source": [
    "matlab -nodisplay -nodesktop -r \"gen_skeletons_warped_single\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e3872-e5b0-4a38-9c48-3325523f39dd",
   "metadata": {},
   "source": [
    "## Step 7: Convert skeletons into graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1ee44-41e0-43c0-916c-1e39b822aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from novas3d.vessel_graph import GraphGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdbeda3-5492-49a6-b334-e50202bd2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('novas3d_example_data/matched_stacks.pickle', 'rb') as handle:\n",
    "        dic = pickle.load(handle)\n",
    "        \n",
    "directory = Path('novas3d_example_data/raw_warped_seg')\n",
    "files_seg_0001 = directory.glob('*_0001_warped_seg.npy')\n",
    "files_seg_0001 = sorted([x.as_posix() for x in files_seg_0001])\n",
    "files_seg_0001 = [x for x in files_seg_0001 if  any(y in x for y in list(dic.keys()))]\n",
    "shuffle(files_seg_0001)\n",
    "\n",
    "\n",
    "params = {'IOU_thresh':0.2,\n",
    "        'initial_suffix':'_warped_seg.npy',\n",
    "        'initial_suffix_mat':'_skel_warped_single.mat',\n",
    "        'final_suffix_npy':'_seg_warped_single.npy',\n",
    "        'final_suffix_pickle':'_warped.pickle',\n",
    "        'final_suffix_tif':'_single_skel.tif',\n",
    "        'timepoint_suffixes':['_0001'],\n",
    "        'ref_timepoint':'_0001',\n",
    "        'thresh_remove_terminal_segemnts':5,\n",
    "        'input_directory':'raw_warped_single_upsampled_seg',\n",
    "        'output_directory':'raw_warped_single_upsampled_seg',\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51e417-45db-4bd1-9f01-68ac8e6400dd",
   "metadata": {},
   "source": [
    "*class GraphGenerator(files, dic, in_directory, out_directory, in_suffix, final_suffix_pickle, in_suffix_mat, final_suffix_tif, ref_timepoint, timepoint_suffixes, IOU_thresh, thresh_remove_terminal_segemnts, skip_existing=False)*\n",
    "\n",
    "Generates graphs based on input files and parameters. Saves the graphs as pickle files.\n",
    "\n",
    "**Args:**\n",
    "- **files (list):** List of input file paths.\n",
    "- **dic (dict):** Dictionary containing paired files. Key is the reference file and value is a list of matching files.\n",
    "- **in_directory (str):** Path to the input directory.\n",
    "- **out_directory (str):** Path to the output directory.\n",
    "- **in_suffix (str):** Suffix of the initial files.\n",
    "- **final_suffix_pickle (str):** Suffix of the final pickle files.\n",
    "- **final_suffix_mat (str):** Suffix of the final mat files.\n",
    "- **final_suffix_tif (str):** Suffix of the final tif files.\n",
    "- **ref_timepoint (str):** Reference timepoint.\n",
    "- **timepoint_suffixes (list):** List of timepoint suffixes.\n",
    "- **IOU_thresh (float):** IOU threshold.\n",
    "- **thresh_remove_terminal_segments (int):** Threshold to remove terminal segments.\n",
    "- **skip_existing (bool):** Skip existing files that have already been processed.\n",
    "\n",
    "**Methods:**\n",
    "- **process_files():** Process the input files and generate graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4624b49-c368-4dad-9e87-76f6c04b9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MakeGraphs = GraphGenerator(files = files_seg_0001,\n",
    "                            dic = dic, \n",
    "                            in_directory=params['input_directory'], \n",
    "                            out_directory = params['output_directory'], \n",
    "                            in_suffix = params['initial_suffix'], \n",
    "                            final_suffix_pickle = params['final_suffix_pickle'], \n",
    "                            in_suffix_mat = params['initial_suffix_mat'], \n",
    "                            final_suffix_tif = params['final_suffix_tif'], \n",
    "                            ref_timepoint = params['ref_timepoint'], \n",
    "                            timepoint_suffixes = params['timepoint_suffixes'], \n",
    "                            IOU_thresh = params['IOU_thresh'], \n",
    "                            thresh_remove_terminal_segemnts = params['thresh_remove_terminal_segemnts'],\n",
    "                            skip_existing=True)\n",
    "\n",
    "MakeGraphs.generate_graphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217ad8d-c61c-48bd-bf9a-2cae8d7787c7",
   "metadata": {},
   "source": [
    "## Step 8: Calculate radii for vessel segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d8bec-81e6-4d7f-aa0c-8df07d750e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy.random import shuffle\n",
    "from pathlib import Path\n",
    "from re import sub\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from novas3d.vessel_graph import VesselRadiiCalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75dcc2-471e-42c9-9134-d5ac12eeba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'in_directory': 'novas3d_example_data/raw_warped_seg',\n",
    "    'img_directory': 'novas3d_example_data/raw_warped',\n",
    "    'mean_directory': 'novas3d_example_data/raw_warped_seg',\n",
    "    'std_directory': 'novas3d_example_data/raw_warped_seg',\n",
    "    'out_directory': 'novas3d_example_data/graphs',\n",
    "    'pickle_file_suffix': '_warped.pickle',\n",
    "    'out_pickle_suffix': '_radii.pickle',\n",
    "    'img_suffix': '_warped.tif',\n",
    "    'seg_suffix': '_warped_seg.npy',\n",
    "    'mean_suffix': '_warped_mean.npy',\n",
    "    'std_suffix': '_warped_std.npy',\n",
    "    'neuron_distance_suffix': '_warped_seg_nrn_dst.npy',\n",
    "    'second_channel': True,\n",
    "    'neuron_channel': True,\n",
    "    'psf': array([0.636,0.127,0.127]),\n",
    "    'spacing': (1,1,2.645833333),\n",
    "    'vessel_segment_limit': 2000,\n",
    "    'max_pixel_value': 1023,\n",
    "    'n_iter_deconv': 10,\n",
    "    'grid_size_psf_deconv': 31, # must be odd number\n",
    "    'sampling': 1/5,\n",
    "    'n_cores':16\n",
    "}\n",
    "\n",
    "if not exists(params['out_directory']):\n",
    "    mkdir(params['out_directory'])\n",
    "\n",
    "directory = Path(params['in_directory'])\n",
    "files = directory.glob('*' + params['pickle_file_suffix'])\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "files = [x for x in files if '-' in x]\n",
    "files = [x for x in files if not exists(sub(params['in_directory'],params['out_directory'],sub(params['pickle_file_suffix'],params['out_pickle_suffix'],x)))]\n",
    "print(len(files))\n",
    "shuffle(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cbad6-aae4-469f-804a-8977f6e63f40",
   "metadata": {},
   "source": [
    "*class VesselRadiiCalc(files, in_directory, img_directory, mean_directory, std_directory, out_directory, pickle_file_suffix, out_pickle_suffix, img_suffix, seg_suffix, mean_suffix, std_suffix, neuron_distance_suffix, second_channel, neuron_channel, psf, spacing, vessel_segment_limit, max_pixel_value, n_iter_deconv, grid_size_psf_deconv, sampling, n_cores, filter_radii = False, butter_N = None, butter_Wn = None, butter_btype = None, butter_fs = None, skip_existing=False)*\n",
    "Initializes an instance of the `VesselRadiiCalc` class. Calculates the radii of vessels based on given parameters and saves the radii in the graph.\n",
    "\n",
    "**Args:**\n",
    "- **files (list):** List of file paths.\n",
    "- **in_directory (str):** Input directory path.\n",
    "- **img_directory (str):** Image directory path.\n",
    "- **mean_directory (str):** Mean directory path.\n",
    "- **std_directory (str):** Standard deviation directory path.\n",
    "- **out_directory (str):** Output directory path.\n",
    "- **pickle_file_suffix (str):** Suffix of the pickle files.\n",
    "- **out_pickle_suffix (str):** Suffix of the output pickle files.\n",
    "- **img_suffix (str):** Suffix of the image files.\n",
    "- **seg_suffix (str):** Suffix of the segmented files.\n",
    "- **mean_suffix (str):** Suffix of the mean files.\n",
    "- **std_suffix (str):** Suffix of the standard deviation files.\n",
    "- **neuron_distance_suffix (str):** Suffix of the neuron distance files.\n",
    "- **second_channel (bool):** Second channel flag. Denotes the presence of a second channel.\n",
    "- **neuron_channel (bool):** Neuron channel flag. Denotes the presence of a neuron channel.\n",
    "- **psf (list):** Point spread function.\n",
    "- **spacing (float):** Spacing value for pixel size along each axis.\n",
    "- **vessel_segment_limit (int):** Vessel segment limit. If larger than the limit, the file is skipped.\n",
    "- **max_pixel_value (int):** Maximum pixel value.\n",
    "- **n_iter_deconv (int):** Number of iterations for deconvolution.\n",
    "- **grid_size_psf_deconv (int):** Grid size for deconvolution. This must be an odd number.\n",
    "- **sampling (float):** Sampling in microns to calculate the radii.\n",
    "- **n_cores (int):** Number of cores.\n",
    "- **filter_radii (bool):** Filter radii with a Butterworth filter.\n",
    "- **butter_N (int):** Butterworth filter order.\n",
    "- **butter_Wn (float):** Butterworth filter frequency.\n",
    "- **butter_btype (str):** Butterworth filter type.\n",
    "- **butter_fs (float):** Butterworth filter frequency.\n",
    "- **skip_existing (bool):** Skip existing files that have already been processed.\n",
    "\n",
    "**Returns:**\n",
    "- Saves the radii in the graph, along with the standard deviation of the radius estimates along the path.\n",
    "- If the `filter_radii` flag is set to `True`, the radii are filtered with a Butterworth filter and saved under the `path_weights` key in the graph. The unfiltered radii are saved under the `path_weights_unfiltered` key in the graph.\n",
    "- If the `filter_radii` flag is set to `False`, the radii are saved as is under the `path_weights` key in the graph.\n",
    "- In both cases, the mean radii estimate is calculated from unfiltered radii estimates and saved under the `radii` key in the graph.\n",
    "- The standard deviation of the radii estimates is calculated and saved under the `radii_std` key in the graph.\n",
    "- If `neuron_channel` is set to `True`, the mean distance to the closest neuron is calculated and saved under the `mean_neuron_distance` key in the graph.\n",
    "- If `neuron_channel` is set to `True`, the standard deviation of the distance to the closest neuron is calculated and saved under the `neuron_distance_std` key in the graph.\n",
    "- If `neuron_channel` is set to `True`, the distance to the closest neuron is saved under the `neuron_distance_min` key in the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac6ab0-6d67-4427-90cc-8301afe96ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vesselRadiusEstimator = VesselRadiiCalc(files,\n",
    "                                        params['in_directory'],\n",
    "                                        params['img_directory'],\n",
    "                                        params['mean_directory'],\n",
    "                                        params['std_directory'],\n",
    "                                        params['out_directory'],\n",
    "                                        params['pickle_file_suffix'],\n",
    "                                        params['out_pickle_suffix'],\n",
    "                                        params['img_suffix'],\n",
    "                                        params['seg_suffix'],\n",
    "                                        params['mean_suffix'],\n",
    "                                        params['std_suffix'],\n",
    "                                        params['neuron_distance_suffix'],\n",
    "                                        params['second_channel'],\n",
    "                                        params['neuron_channel'],\n",
    "                                        params['psf'],\n",
    "                                        params['spacing'],\n",
    "                                        params['vessel_segment_limit'],\n",
    "                                        params['max_pixel_value'],\n",
    "                                        params['n_iter_deconv'],\n",
    "                                        params['grid_size_psf_deconv'],\n",
    "                                        params['sampling'],\n",
    "                                        params['n_cores'],\n",
    "                                        skip_exsiting=True)\n",
    "vesselRadiusEstimator.process_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27180a1d-3945-4eb2-9218-b9e7e81057d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai3.8",
   "language": "python",
   "name": "monai3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
