{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c772a4f6-3278-4605-a9a4-c6a3995c6fd1",
   "metadata": {},
   "source": [
    "# Tutorial for extracting graph represenatations of all images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2131d7a-3cc8-416b-9e0c-415a222a9abb",
   "metadata": {},
   "source": [
    "## Step 1: Register images from the same FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa32a8-1818-4e30-bade-5be2e32b8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "from pathlib import Path\n",
    "from vessel_morphology.registration import ImageRegistration\n",
    "import pickle\n",
    "from os import mkdir\n",
    "from os.path import exists\n",
    "from vessel_morphology.utilities import get_mov_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aadd00d-3a0b-44ee-bab9-3b6f28d5ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dictionary for matched volumes\n",
    "with open('test_data/matched_stacks_init.pickle', 'rb') as f:\n",
    "    dic = pickle.load(f)\n",
    "sorted(dic['67/XYZres387'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d3986-cbd5-42ba-b94a-3584251e1d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids_path = Path('test_data/THY1')#each mouse has its own folder with raw data in it\n",
    "mouse_ids = list(mouse_ids_path.glob('*?[0-9]/*res*?[0-9].tif'))#grab folder names/mouse ids\n",
    "images = sorted([x.as_posix() for x in mouse_ids if '_0001' not in x.as_posix()])\n",
    "images = [x for x in images if  any(y in x for y in list(dic.keys()))]\n",
    "\n",
    "unused_keys = [x for x in list(dic.keys()) if not  any(x in y for y in images)]\n",
    "print(len(images))\n",
    "shuffle(images)\n",
    "params = { \n",
    "    'out_directory': 'test_data/raw_warped/', # path to output directory\n",
    "    'initial_filename_extension': '.tif', # initial filename extension of unregistered images\n",
    "    'final_filename_extension': '_warped.tif', # modified filename extension following registration\n",
    "    'timepoint_suffixes': ['_0001'], # list of all timepoint suffixes present ie _0001, _0002, _0003, ...\n",
    "    'sigma': 2, # Smoothing sigma applied to iamges prior to registration, used by ANTs rigid registration\n",
    "    'flip': True, # flip images based on direction of aquision to match the reference. ONly works for files that were origionally olympus oir files\n",
    "    'dic': dic # dictionary of matched aqusitions\n",
    "}\n",
    "\n",
    "if not exists(params['out_directory']):\n",
    "    mkdir(params['out_directory'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d73ad7-92e8-45fc-b159-3428bf9fa671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ImageRegistration class\n",
    "registration = ImageRegistration(images = images, \n",
    "                                 out_directory = params['out_directory'], \n",
    "                                 initial_filename_extension = params['initial_filename_extension'], \n",
    "                                 final_filename_extension = params['final_filename_extension'], \n",
    "                                 timepoint_suffixes = params['timepoint_suffixes'], \n",
    "                                 sigma = params['sigma'], \n",
    "                                 flip = params['flip'], \n",
    "                                 dic = params['dic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e09c7-fd84-452d-ab3f-57761d9e5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the register_images method\n",
    "registration.register_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2abe512-a56c-42de-a92c-9f0617eee6e3",
   "metadata": {},
   "source": [
    "## Step 2: Predict segmentation results\n",
    "\n",
    "### !!! Faster With GPUs !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c2be5-b4f4-41eb-b3d8-088608884d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from pathlib import Path\n",
    "from re import sub\n",
    "import warnings\n",
    "from numpy.random import shuffle\n",
    "from vessel_morphology.predict import PredictWarped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe8a1e-783b-438f-920f-f6352529462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the mouse data\n",
    "image_path = Path('test_data/raw_warped')\n",
    "images = list(image_path.glob('*res*.tif'))\n",
    "images = sorted([x.as_posix() for x in images])\n",
    "shuffle(images)\n",
    "\n",
    "# Create data dictionaries for prediction\n",
    "params = {\n",
    "    \"input_dir\": \"test_data/raw_warped\", # imput directory of files to segment\n",
    "    \"output_dir\": \"test_data/raw_warped_seg\", # output directory for files after segmentation\n",
    "    \"num_evals\": 3, # number of evaluations for the ensemble to predict with\n",
    "    \"base_file_extension\": \".tif\", # base file extension\n",
    "    \"pred_file_extension\": \"_pred.npy\", # predicted probabilities filename extension\n",
    "    \"mean_file_extension\": \"_mean.npy\", # mean probabilities filename extension\n",
    "}\n",
    "\n",
    "if not exists(params['output_dir']):\n",
    "    mkdir(params['output_dir'])\n",
    "\n",
    "##################################################################################################################\n",
    "# STD will be calcualted later on an allocation without GPUs, this takes up alot of CPU time leaving GPUs idol\n",
    "##################################################################################################################\n",
    "\n",
    "data_dict = [\n",
    "    {\"image\": image_name}\n",
    "    for image_name in images if not exists(sub(params[\"base_file_extension\"], params[\"pred_file_extension\"], sub(params[\"input_dir\"], params[\"output_dir\"], image_name)))\n",
    "]\n",
    "\n",
    "print(len(data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67969368-f19b-4363-bf0d-39d8e41d2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictMatt = PredictWarped(data_dict, \n",
    "                            params,\n",
    "                            parameter_file='hyperparameter_pickle_files/parameters436.pickle', \n",
    "                            spatial_dims=3, \n",
    "                            in_channels=2, \n",
    "                            out_channels=3, \n",
    "                            img_size=(128,128,128), \n",
    "                            feature_size=16, \n",
    "                            hidden_size=768, \n",
    "                            mlp_dim=3072, \n",
    "                            pos_embed=\"perceptron\",\n",
    "                            res_block=True, \n",
    "                            norm_name=\"instance\",\n",
    "                            spacing=(1, 1, 0.375), \n",
    "                            i_min=0, \n",
    "                            i_max=1024, \n",
    "                            b_min=0.0, \n",
    "                            b_max=1.0, \n",
    "                            clip=True, \n",
    "                            channel_dim=0)\n",
    "PredictMatt.prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089584b-139c-4651-bf0c-020a0e695a19",
   "metadata": {},
   "source": [
    "## Step 3: Calculate STD of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7badb459-42d7-49f6-9e65-0d36eaadeff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from re import sub\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from numpy.random import shuffle\n",
    "from vessel_morphology.vessel_graph import SaveStdFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8cb3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b4876-3b5c-42b1-ab91-871135608865",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"data_directory\": \"test_data/raw_warped_seg\", #location of output probabilities from prediction\n",
    "    \"in_directory\": \"test_data/raw_warped_seg\",\n",
    "    \"out_directory\": \"test_data/raw_warped_seg\",\n",
    "    \"init_tag\": 'pred', # tag for the predicited probabilities array in step 2 \"pred_file_extension\"\n",
    "    \"final_tag\": 'std' # tag to save the standard deviation of the predicted probabiliteis under\n",
    "}\n",
    "\n",
    "if not exists(params['out_directory']):\n",
    "    mkdir(params['out_directory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6d61c-c716-40bf-b744-ec8fd86aaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the files list\n",
    "path = Path(params[\"data_directory\"])\n",
    "files = list(path.glob('*_' + params['init_tag'] + '.npy'))\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "files = [x for x in files if not exists(sub(params['in_directory'], params['out_directory'], sub(params['init_tag'], params['final_tag'], x)))]\n",
    "print(len(files))\n",
    "\n",
    "# Shuffle the files list\n",
    "shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc57f72-1d39-4ad6-af63-81c22a9a1901",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create an instance of the SaveStdFile class with the files list and other parameters\n",
    "save_std = SaveStdFile(files, params['in_directory'], params['out_directory'], params['init_tag'], params['final_tag'])\n",
    "# Save the standard deviation files\n",
    "save_std.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5a203-af19-404f-8612-52a6b7feeb95",
   "metadata": {},
   "source": [
    "## Step 4: Binarize Vascular predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c7855-51c0-410a-8623-0d046dcb29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from numpy.random import shuffle\n",
    "from pathlib import Path\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from vessel_morphology.vessel_graph import Binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b41fe6-7f1c-4297-a0d0-ecddd9d70233",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('test_data/raw_warped_seg')\n",
    "files  = directory.glob('*-*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(len(files))\n",
    "\n",
    "parameters = {\n",
    "    'min_prob': 0.75, # minimum probability for binarization to classify a voxel as a vessel\n",
    "    'max_var': 0.2, # maximum standard deviation for binarization to classify a voxel as a vessel\n",
    "    'in_directory': \"test_data/raw_warped_seg\", # input directory\n",
    "    'out_directory': \"test_data/raw_warped_seg\", # output directory\n",
    "    'mean_tag': 'mean', # tag for mean probaility\n",
    "    'std_tag': 'std', # tag for mean standard deviation of probability\n",
    "    'seg_tag': 'seg' # output tag for segmentation\n",
    "}\n",
    "\n",
    "if not exists(params['out_directory']):\n",
    "    mkdir(params['out_directory'])\n",
    "\n",
    "shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc22b8-d0b4-4dea-9dca-0468b75abeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = Binarize(files = files,\n",
    "                     min_prob = parameters['min_prob'],\n",
    "                     max_var = parameters['max_var'], \n",
    "                     in_directory = parameters['in_directory'],\n",
    "                     out_directory = parameters['out_directory'], \n",
    "                     mean_tag = parameters['mean_tag'],\n",
    "                     std_tag = parameters['std_tag'],\n",
    "                     seg_tag = parameters['seg_tag'])\n",
    "\n",
    "binarizer.binarize_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27b5e8-4279-4022-8c8f-0ff4e488f0a2",
   "metadata": {},
   "source": [
    "## Step 4a: binarize neuron segmentation and calculate distances from every nonneuron pixel to the closest neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dad583-78bb-45e6-8784-c368301bcd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from vessel_morphology.vessel_graph import NeuronDistanceCalculator\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from re import sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e438c-4a36-492c-9d9b-4666aeec0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('test_data/raw_warped_seg')\n",
    "files  = directory.glob('*-*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "files = [x for x in files if not exists(sub('_mean.npy', '_seg_nrn.npy', x))]\n",
    "print(len(files))\n",
    "\n",
    "parameters = {\n",
    "    'min_prob': 0.75,\n",
    "    'max_var': 0.1,\n",
    "    'in_directory': 'test_data/raw_warped_seg',\n",
    "    'out_directory': 'test_data/raw_warped_seg',\n",
    "    'mean_tag': 'mean',\n",
    "    'std_tag': 'std',\n",
    "    'neuron_distance_tag': 'seg_nrn_dst',\n",
    "    'seg_tag': 'seg',\n",
    "    'seg_nrn_tag': 'seg_nrn'   \n",
    "}\n",
    "\n",
    "if not exists(params['out_directory']):\n",
    "    mkdir(params['out_directory'])\n",
    "\n",
    "np.random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42941c-fa8b-42d9-ad82-0dc4ce9caa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = NeuronDistanceCalculator(files, \n",
    "                             parameters['min_prob'], \n",
    "                             parameters['max_var'], \n",
    "                             parameters['in_directory'], \n",
    "                             parameters['out_directory'], \n",
    "                             parameters['mean_tag'], \n",
    "                             parameters['std_tag'], \n",
    "                             parameters['neuron_distance_tag'], \n",
    "                             parameters['seg_tag'], \n",
    "                             parameters['seg_nrn_tag'])\n",
    "n.calculate_distance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d64d1-0f3a-430b-ae23-dd6f44145813",
   "metadata": {},
   "source": [
    "## Step 5: Calculate union of matched files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984eb38a-b4e7-4490-b874-91fefaf91076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "from pathlib import Path\n",
    "from re import sub\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "import pickle\n",
    "from vessel_morphology.vessel_graph import SegmentationMaskUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc74f1-7216-4123-a19a-61a11ef79d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data/matched_stacks.pickle', 'rb') as handle:\n",
    "    dic = pickle.load(handle)\n",
    "    \n",
    "directory_seg = Path('test_data/raw_warped_seg')\n",
    "images = list(directory_seg.glob('*_0001_warped_seg.npy'))\n",
    "images = sorted([x.as_posix() for x in images])\n",
    "images = [x for x in images if exists(sub('_0001','',x))]\n",
    "images = [x for x in images if any(y in x for y in list(dic.keys()))]\n",
    "\n",
    "params = {'IOU_thresh':0.2,\n",
    "        'input_directory':'test_data/raw_warped_seg',\n",
    "        'output_directory':'test_data/raw_warped_seg',\n",
    "        'initial_suffix':'_warped_seg.npy',\n",
    "        'final_suffix_mat':'_seg_warped_single.mat',\n",
    "        'final_suffix_npy':'_seg_warped_single.npy',\n",
    "        'timepoint_suffixes':['_0001'],\n",
    "        'thresh_remove_small_comps':250,\n",
    "        'thresh_fill_holes':1000,\n",
    "        'n_interations_binary_closing':3,\n",
    "        }\n",
    "\n",
    "if not exists(params['output_directory']):\n",
    "    mkdir(params['output_directory'])\n",
    "\n",
    "shuffle(images)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a796e-db29-4746-b564-2d62a374e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ImageProcessor and process the images\n",
    "processor = SegmentationMaskUnion(images, \n",
    "                                         dic,\n",
    "                                         params['input_directory'], \n",
    "                                         params['output_directory'], \n",
    "                                         params['initial_suffix'], \n",
    "                                         params['final_suffix_mat'], \n",
    "                                         params['final_suffix_npy'],\n",
    "                                         params['timepoint_suffixes'], \n",
    "                                         params['IOU_thresh'], \n",
    "                                         params['thresh_fill_holes'], \n",
    "                                         params['thresh_remove_small_comps'],\n",
    "                                         params['n_interations_binary_closing'],\n",
    "                                        )\n",
    "processor.process_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52209fa3-23d8-4c1a-8b52-db1c9204ecfd",
   "metadata": {},
   "source": [
    "## Step 6: Generate Skeletons from the Union of the segmentation masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b059447-e4b3-47c6-be64-c8d9c16ea2af",
   "metadata": {},
   "source": [
    "Run the following code in matlab after modifying the following matlab file gen_skeletons_warped_single.m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a4986-e2dd-4374-893c-3333b58b68f7",
   "metadata": {},
   "source": [
    "module load matlab \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008a1ac-cf98-499c-8cc5-d2de08927b43",
   "metadata": {},
   "source": [
    "matlab -nodisplay -nodesktop -r \"gen_skeletons_warped_single\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e3872-e5b0-4a38-9c48-3325523f39dd",
   "metadata": {},
   "source": [
    "## Step 7: Convert skeletons into graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c1ee44-41e0-43c0-916c-1e39b822aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "#from vessel_morphology.vessel_graph import GraphGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cdbeda3-5492-49a6-b334-e50202bd2a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "with open('test_data/matched_stacks.pickle', 'rb') as handle:\n",
    "        dic = pickle.load(handle)\n",
    "        \n",
    "directory = Path('test_data/raw_warped_seg')\n",
    "files_seg_0001 = directory.glob('*_0001_warped_seg.npy')\n",
    "files_seg_0001 = sorted([x.as_posix() for x in files_seg_0001])\n",
    "files_seg_0001 = [x for x in files_seg_0001 if  any(y in x for y in list(dic.keys()))]\n",
    "shuffle(files_seg_0001)\n",
    "print(len(files_seg_0001))\n",
    "\n",
    "params = {'IOU_thresh':0.2,\n",
    "        'initial_suffix':'_warped_seg.npy',\n",
    "        'initial_suffix_mat':'_skel_warped_single.mat',\n",
    "        'final_suffix_npy':'_seg_warped_single.npy',\n",
    "        'final_suffix_pickle':'_warped.pickle',\n",
    "        'final_suffix_tif':'_single_skel.tif',\n",
    "        'timepoint_suffixes':['_0001'],\n",
    "        'ref_timepoint':'_0001',\n",
    "        'thresh_remove_terminal_segemnts':20,\n",
    "        'input_directory':'raw_warped_single_upsampled_seg',\n",
    "        'output_directory':'raw_warped_single_upsampled_seg',\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced5b51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_data/raw_warped_seg/67-XYZres387_0001_warped_seg.npy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_seg_0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b0db78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from re import sub\n",
    "from scipy.io import savemat, loadmat\n",
    "import numpy as np\n",
    "from sknw import build_sknw\n",
    "from importlib.metadata import version as ver\n",
    "#skel_file = 'test_data/raw_warped_seg/67-XYZres387_0001_skel_warped_single.mat'\n",
    "skel_file = sub(params['ref_timepoint'] + params['initial_suffix'], params['initial_suffix_mat'], files_seg_0001[0]) \n",
    "os.path.exists(skel_file)\n",
    "skel = loadmat(skel_file)['FilteredImage']\n",
    "\n",
    "import threading\n",
    "#print(ver(threading))\n",
    "\n",
    "import faulthandler\n",
    "faulthandler.enable()\n",
    "PYTHONFAULTHANDLER = 1\n",
    "\n",
    "\n",
    "#if np.sum(skel) != 0:\n",
    "#    # Build a graph representation of the skeleton\n",
    "#    graph = build_sknw(skel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d445f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56.3\n",
      "2.6.3\n",
      "1.23.0\n",
      "0.1\n",
      "0.39.1\n",
      "69.5.1\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "print(numba.__version__)\n",
    "import networkx\n",
    "print(networkx.__version__)\n",
    "import numpy\n",
    "print(numpy.__version__)\n",
    "import sknw\n",
    "print(sknw.__version__)\n",
    "#import importlib_metadata\n",
    "#print(importlib_metadata.__version__)\n",
    "#import zipp\n",
    "#print(zipp.__version__)\n",
    "import llvmlite\n",
    "print(llvmlite.__version__)\n",
    "import setuptools\n",
    "print(setuptools.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e133be1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'package_deps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackage_deps\u001b[39;00m\n\u001b[1;32m      2\u001b[0m package \u001b[38;5;241m=\u001b[39m package_deps\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msknw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(package\u001b[38;5;241m.\u001b[39mdependencies)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'package_deps'"
     ]
    }
   ],
   "source": [
    "import package_deps\n",
    "package = package_deps.find('sknw')\n",
    "print(package.dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4624b49-c368-4dad-9e87-76f6c04b9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "import sys\n",
    "sys.settrace\n",
    "\n",
    "MakeGraphs = GraphGenerator(files = files_seg_0001,\n",
    "                            dic = dic, \n",
    "                            in_directory=params['input_directory'], \n",
    "                            out_directory = params['output_directory'], \n",
    "                            in_suffix = params['initial_suffix'], \n",
    "                            final_suffix_pickle = params['final_suffix_pickle'], \n",
    "                            in_suffix_mat = params['initial_suffix_mat'], \n",
    "                            final_suffix_tif = params['final_suffix_tif'], \n",
    "                            ref_timepoint = params['ref_timepoint'], \n",
    "                            timepoint_suffixes = params['timepoint_suffixes'], \n",
    "                            IOU_thresh = params['IOU_thresh'], \n",
    "                            thresh_remove_terminal_segemnts = params['thresh_remove_terminal_segemnts'])\n",
    "faulthandler.enable()\n",
    "MakeGraphs.generate_graphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217ad8d-c61c-48bd-bf9a-2cae8d7787c7",
   "metadata": {},
   "source": [
    "## Step 8: Calculate radii for vessel segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d8bec-81e6-4d7f-aa0c-8df07d750e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy.random import shuffle\n",
    "from pathlib import Path\n",
    "from re import sub\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from vessel_morphology.vessel_graph import VesselRadiiCalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75dcc2-471e-42c9-9134-d5ac12eeba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'in_directory': 'test_data/raw_warped_seg',\n",
    "    'img_directory': 'test_data/raw_warped',\n",
    "    'mean_directory': 'test_data/raw_warped_seg',\n",
    "    'std_directory': 'test_data/raw_warped_seg',\n",
    "    'out_directory': 'test_data/graphs',\n",
    "    'pickle_file_suffix': '_warped.pickle',\n",
    "    'out_pickle_suffix': '_radii.pickle',\n",
    "    'img_suffix': '_warped.tif',\n",
    "    'seg_suffix': '_warped_seg.npy',\n",
    "    'mean_suffix': '_warped_mean.npy',\n",
    "    'std_suffix': '_warped_std.npy',\n",
    "    'neuron_distance_suffix': '_warped_seg_nrn_dst.npy',\n",
    "    'second_channel': True,\n",
    "    'neuron_channel': True,\n",
    "    'psf': array([0.636,0.127,0.127]),\n",
    "    'spacing': (1,1,2.645833333),\n",
    "    'vessel_segment_limit': 2000,\n",
    "    'max_pixel_value': 1023,\n",
    "    'n_iter_deconv': 10,\n",
    "    'grid_size_psf_deconv': 31, # must be odd number\n",
    "    'sampling': 1/5,\n",
    "    'n_cores':16\n",
    "}\n",
    "\n",
    "if not exists(params['out_directory']):\n",
    "    mkdir(params['out_directory'])\n",
    "\n",
    "directory = Path(params['in_directory'])\n",
    "files = directory.glob('*' + params['pickle_file_suffix'])\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "files = [x for x in files if '-' in x]\n",
    "files = [x for x in files if not exists(sub(params['in_directory'],params['out_directory'],sub(params['pickle_file_suffix'],params['out_pickle_suffix'],x)))]\n",
    "print(len(files))\n",
    "shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac6ab0-6d67-4427-90cc-8301afe96ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vesselRadiusEstimator = VesselRadiiCalc(files,\n",
    "                                        params['in_directory'],\n",
    "                                        params['img_directory'],\n",
    "                                        params['mean_directory'],\n",
    "                                        params['std_directory'],\n",
    "                                        params['out_directory'],\n",
    "                                        params['pickle_file_suffix'],\n",
    "                                        params['out_pickle_suffix'],\n",
    "                                        params['img_suffix'],\n",
    "                                        params['seg_suffix'],\n",
    "                                        params['mean_suffix'],\n",
    "                                        params['std_suffix'],\n",
    "                                        params['neuron_distance_suffix'],\n",
    "                                        params['second_channel'],\n",
    "                                        params['neuron_channel'],\n",
    "                                        params['psf'],\n",
    "                                        params['spacing'],\n",
    "                                        params['vessel_segment_limit'],\n",
    "                                        params['max_pixel_value'],\n",
    "                                        params['n_iter_deconv'],\n",
    "                                        params['grid_size_psf_deconv'],\n",
    "                                        params['sampling'],\n",
    "                                        params['n_cores'])\n",
    "vesselRadiusEstimator.process_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27180a1d-3945-4eb2-9218-b9e7e81057d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
